{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 2: Training des Modells\n",
    "\n",
    "Im Unterverzeichnis `04-sheets` sollten nun viele Bilddateien mit 28x28 Pixel gro√üen Ziffern liegen. Wir laden die Bilder, extrahieren das jeweilige Label aus dem Dateinamen und konstruieren ein k√ºnstliches neuronales Netzwerk. 60% der Daten nutzen wir f√ºr das Training, 20% f√ºr die Validierung, und 20% f√ºr den Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "SHEETS_DIR = '04-sheets'\n",
    "MODEL_DIR = '05-model'\n",
    "\n",
    "images, labels = [], []\n",
    "DIGITS = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ√Ñ√ñ√ú√ü'\n",
    "\n",
    "for path in glob.glob(os.path.join(SHEETS_DIR, \"*\")):\n",
    "    img = Image.open(path).convert('L')\n",
    "    image = np.array(img)\n",
    "    height, width = image.shape\n",
    "    for i in range(0, height, 28):\n",
    "        for j in range(0, width, 28):\n",
    "            sub = image[i:i+28, j:j+28]\n",
    "            if not np.all(sub == 255):\n",
    "                images.append(sub / 255.0)\n",
    "                labels.append(DIGITS.index(os.path.basename(path).split('.')[0].split('_')[0]))\n",
    "\n",
    "train_x, train_y = np.array(images), np.array(labels)\n",
    "data = list(zip(train_x, train_y))\n",
    "np.random.shuffle(data)\n",
    "\n",
    "train_data = data[:int(len(data)*0.6)]\n",
    "valid_data = data[int(len(data)*0.6):int(len(data)*0.8)]\n",
    "test_data = data[int(len(data)*0.8):]\n",
    "\n",
    "train_x, train_y = zip(*train_data)\n",
    "valid_x, valid_y = zip(*valid_data)\n",
    "test_x, test_y = zip(*test_data)\n",
    "\n",
    "train_x, train_y = np.array(train_x), np.array(train_y)\n",
    "valid_x, valid_y = np.array(valid_x), np.array(valid_y)\n",
    "test_x, test_y = np.array(test_x), np.array(test_y)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Alternativ zu deinen eigenen Daten kannst du\n",
    "# auch den MNIST-Datensatz verwenden.\n",
    "# Kommentiere daf√ºr diesen Block aus:\n",
    "# --------------------------------------------\n",
    "# mnist = tf.keras.datasets.mnist.load_data()\n",
    "# (train_full_x, train_full_y), (test_x, test_y) = mnist\n",
    "# train_x, train_y = train_full_x[:-5000], train_full_y[:-5000]\n",
    "# valid_x, valid_y = train_full_x[-5000:], train_full_y[-5000:]\n",
    "# train_x, valid_x, test_x = 1.0 - train_x / 255.0, 1.0 - valid_x / 255.0, 1.0 - test_x / 255.0\n",
    "\n",
    "print(f\"‚úÖ Trainingsdaten: {train_y.shape[0]}, Validierungsdaten: {valid_y.shape[0]}, Testdaten: {test_y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(40, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsphase\n",
    "\n",
    "Als n√§chstes wird das Netzwerk trainiert und das resultierende Modell gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, epochs=30, validation_data=(valid_x, valid_y))\n",
    "model.save(\"my_keras_model.h5\")\n",
    "print(\"‚úÖ Modell trainiert und gespeichert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualit√§t des Modells\n",
    "\n",
    "Wir lassen uns die Qualit√§t des Modell ausgeben, indem wir Loss und Accuracy des Test-Sets bestimmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"Das trainierte Modell erreicht einen Loss von {:.4f} und eine Accuracy von {:.2f}% auf dem Testdatensatz.\".format(loss, accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir probieren nun anhand einiger zuf√§llig gew√§hlter Ziffern aus, was das Modell erkennt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images_with_labels(images, labels, correct_labels, indices):\n",
    "    fig, axes = plt.subplots(5, 20, figsize=(10, 3.5))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(100):\n",
    "        k = indices[i]\n",
    "        axes[i].imshow(images[k].reshape(28, 28), cmap='gray')\n",
    "        axes[i].set_title(f\"{DIGITS[labels[k]]}\", fontsize=9, color='black' if labels[k] == correct_labels[k] else 'red')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "indices = [_ for _ in range(len(test_x))]\n",
    "np.random.shuffle(indices)\n",
    "plot_images_with_labels(test_x, model.predict(test_x).argmax(axis=1), test_y, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konvertierung des Modells\n",
    "\n",
    "Dein trainiertes Modell besteht nun aus allen Gewichten und Bias-Werten ‚Äì es befindet sich in der Datei `my_keras_model.h5`.\n",
    "\n",
    "Wir m√∂chten nun das neuronale Netz interaktiv testen, wof√ºr sich JavaScript im Browser anbietet, da wir hier leicht Eingaben mit der Maus machen k√∂nnen. Daf√ºr m√ºssen wir das Modell zun√§chst in ein Format konvertieren, das von JavaScript gelesen werden kann. Gehe hierzu auf die Seite [https://tf.hackschule.de/](https://tf.hackschule.de/) und konvertiere dein Modell.\n",
    "\n",
    "Du erh√§ltst eine ZIP-Datei, in der sich zwei Dateien befinden. Diese musst du beide in das Verzeichnis `05-model` kopieren. Stelle anschlie√üend sicher, dass sich die drei Dateien `index.html`, `index.js` und `worker.js` im Projektverzeichnis befinden (also nicht in `05-model`, sondern dar√ºber ‚Äì im selben Verzeichnis wie dieses Notebook).\n",
    "\n",
    "## Interaktiver Test\n",
    "\n",
    "Starte den HTTP-Server, indem du unten rechts auf ¬ªLive Server¬´ klickst.\n",
    "\n",
    "Du kannst nun im Browser links oben in der Fl√§che zeichnen (linke Maustaste: zeichnen, rechte Maustaste: l√∂schen). Dabei kannst du beobachten, wir die Informationen durch das k√ºnstliche neuronale Netzwerk laufen und am Ende eine Vorhersage getroffen wird, um welche Ziffer es sich handelt.\n",
    "\n",
    "_Eigentlich gibt es ein Kommanozeilen-Programm, das diese Konvertierung durchf√ºhrt und das ist auch genau das, was auf tf.hackschule.de passiert. Ich habe das Tool in der Schule nur nicht zum Laufen bekommen, weshalb ich schnell diese kleine Seite gebastelt habe, die den Job √ºbernimmt._ üòâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
